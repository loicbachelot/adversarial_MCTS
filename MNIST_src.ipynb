{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_src.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxtO_vyl2j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import models, layers, Sequential, optimizers, metrics\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "import skimage.util as sk\n",
        "from skimage.util.shape import view_as_blocks\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBLKSxI5mFLj",
        "colab_type": "text"
      },
      "source": [
        "##Data creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPZ5IY1nJ-tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load('mnist_perso_train.npy')\n",
        "data = np.reshape(data, (60000, 27, 27))\n",
        "\n",
        "data_size = 30000\n",
        "global_count = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMvJSVvfoZGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getRealImg(number, step):\n",
        "  listImg = []\n",
        "  for i in range(number):\n",
        "    img = np.array(data[np.random.randint(data_size)+data_size])    \n",
        "    listImg.append(img.reshape(-1))\n",
        "  return np.array(listImg)\n",
        "\n",
        "def getTrainingD(generatedImg, batchsize, step):\n",
        "  trainDataD = np.concatenate((generatedImg, getRealImg(batchsize, step)))\n",
        "  trainLabelsD = np.concatenate((np.zeros(batchsize), np.ones(batchsize)))\n",
        "  return trainDataD, trainLabelsD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoxR7q9J2J10",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd6rW8vo0PQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p=9 #positions\n",
        "f=9 #fragments\n",
        "d=81 #dim encodage fragment\n",
        "D=f*d #dim encodage F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzxomWQM2YqN",
        "colab_type": "text"
      },
      "source": [
        "##Generative Custom layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLlXBac32V6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MagicLayer(layers.Layer):\n",
        "    def __init__(self, f, d, D):\n",
        "        super(MagicLayer, self).__init__()\n",
        "        self.p = 9\n",
        "        self.f = f\n",
        "        self.d = d\n",
        "        self.D = D\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\"kernel\", shape=[p, self.d, self.D], trainable=True)\n",
        "        self.bias = self.add_weight(\"bias\", shape=[self.D], trainable=True)\n",
        "    \n",
        "    def call(self, input):\n",
        "        assert isinstance(input, list)\n",
        "        A, B = input        \n",
        "        x = tf.einsum('pdD,bfd->bfpD', self.kernel, A)\n",
        "        B_biased = tf.add(B, self.bias)\n",
        "        x = tf.einsum('bD,bfpD->bfp', B_biased, x)\n",
        "        x = tf.layers.flatten(x)#flatten\n",
        "        return tf.nn.leaky_relu(x, 0.1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        return (input_shape[0], self.D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKx65ad23CVU",
        "colab_type": "text"
      },
      "source": [
        "##Generative Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7T1XgFs3FFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fi_single_extractor_CNN():\n",
        "  extractor_inputs = layers.Input(shape=(81,))\n",
        "  fi_extractor_out = layers.Reshape((9, 9, 1))(extractor_inputs)\n",
        "  fi_extractor_out = layers.Conv2D(32, (3, 3), use_bias=False, padding='same')(fi_extractor_out)\n",
        "  fi_extractor_out = layers.MaxPooling2D((2, 2))(fi_extractor_out)\n",
        "  fi_extractor_out = layers.Flatten()(fi_extractor_out)\n",
        "  fi_extractor_out = layers.Dense(81, activation='relu')(fi_extractor_out)\n",
        "  return models.Model(inputs=extractor_inputs, outputs=fi_extractor_out)\n",
        "\n",
        "def get_fi_single_extractor_FC():\n",
        "  extractor_inputs = layers.Input(shape=(81,))\n",
        "  fi_extractor_out = layers.Dense(81, activation='relu')(extractor_inputs)\n",
        "  return models.Model(inputs=extractor_inputs, outputs=fi_extractor_out)\n",
        "\n",
        "\n",
        "def ccx(labels, output):\n",
        "    return tf.sign(labels)*tf.square(output-labels)\n",
        "\n",
        "def get_Gnetwork():\n",
        "    \n",
        "    #System inputs\n",
        "    fi = layers.Input(shape=(f, d))\n",
        "    F = layers.Input(shape=(D,))\n",
        "    \n",
        "    #noise = layers.GaussianNoise(0.1)\n",
        "    magic = MagicLayer(f, d, D)\n",
        "    \n",
        "    #fragment extractor    \n",
        "    fi_extractor = get_fi_single_extractor_CNN()\n",
        "    fi_2 = layers.TimeDistributed(fi_extractor)(fi)\n",
        "    \n",
        "    #image extractor                                  \n",
        "    F_2 = layers.Reshape((27, 27, 1))(F)\n",
        "    F_2  = layers.Conv2D(32, (5, 5), activation='relu', padding='same')(F_2)\n",
        "    F_2 = layers.MaxPooling2D((2, 2))(F_2)\n",
        "    F_2 = layers.Flatten()(F_2)\n",
        "    F_2 = layers.Dense(9*81, activation='relu')(F_2)\n",
        "    \n",
        "    output = magic([fi_2, F_2])\n",
        "    #output = layers.Dropout(0.5)(output)\n",
        "\n",
        "    network = models.Model(inputs=[fi, F], outputs=output)\n",
        "    network.compile(optimizer=optimizers.RMSprop(lr=0.00001, rho=0.9, epsilon=None, decay=0.0), loss=ccx, metrics=['accuracy'])\n",
        "    return network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB_gPBxgSY4C",
        "colab_type": "text"
      },
      "source": [
        "##Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBIDOPCrShew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDnetwork():\n",
        "  model = Sequential()\n",
        "  model.add(layers.Reshape((27, 27, 1)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='mean_squared_error', optimizer=optimizers.RMSprop(lr=0.000005), metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J95kiTlWZMxm",
        "colab_type": "text"
      },
      "source": [
        "##World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U07MIVM8ZLyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class World():\n",
        "    def __init__(self,  inputImg, permutation=True):\n",
        "        self.permutation = permutation\n",
        "        self.inputImg = inputImg\n",
        "        self.history = []\n",
        "        self.fi_table = np.random.permutation(9)\n",
        "        self.initialize()\n",
        "    \n",
        "    def initialize(self):\n",
        "        self.t = 0\n",
        "        self.F, self.F_mask = np.ones(27*27).reshape(27, 27)*(-0.1), np.full(9, False)\n",
        "        \n",
        "        #random selection\n",
        "        if self.inputImg < 0:\n",
        "          img = data[np.random.randint(data_size)]\n",
        "        else:\n",
        "          img = data[self.inputImg]\n",
        "        \n",
        "        self.fi = np.array(view_as_blocks(img, block_shape=(9, 9))).reshape(9, 81)\n",
        "        \n",
        "        if (self.permutation):\n",
        "            self.fi = self.fi[self.fi_table]\n",
        "            self.fi_mask = np.full(9, True)\n",
        "            self.pi = self.fi.copy()\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return \"<t:%d \\nfi: \\n%s\\n%s \\nF:\\n%s\\n%s \\npi:\\n%s>\" % (self.t, self.fi, self.fi_mask, self.F, self.F_mask, self.pi)\n",
        "    \n",
        "    def legal_move(self, action):\n",
        "        index_fi, index_F = action\n",
        "        return self.fi_mask[index_fi] and not self.F_mask[index_F]\n",
        "    \n",
        "    def move(self, action):\n",
        "        if not self.legal_move(action):\n",
        "            return False\n",
        "        \n",
        "        index_fi, index_F = action\n",
        "        self.t += 1\n",
        "        \n",
        "        #add the new fragment on the image\n",
        "        self.F[9*(index_F%3):9*((index_F%3)+1) , 9*(index_F//3):9*((index_F//3)+1)] = self.fi[index_fi].reshape(9,9)\n",
        "        \n",
        "        self.F_mask[index_F] = True\n",
        "        self.fi[index_fi] = -1\n",
        "        self.fi_mask[index_fi] = False\n",
        "        self.pi[index_fi] = -1\n",
        "        self.pi[:,index_F] = 0\n",
        "        self.history.append(action)\n",
        "\n",
        "        \n",
        "    def get_random_move(self):\n",
        "        index_fi = np.random.choice(np.where(self.fi_mask == True)[0])\n",
        "        index_F = np.random.choice(np.where(self.F_mask == False)[0])\n",
        "        return (index_fi, index_F)\n",
        "    \n",
        "    def best_legal_move(self, P, rand_choice):\n",
        "        h,w = np.shape(P)\n",
        "        \n",
        "        if self.inputImg < 0: #add noise for a better exploration on the training\n",
        "          if np.random.random() < rand_choice:\n",
        "            return self.get_random_move()\n",
        "          \n",
        "        P[np.where(self.fi_mask == False)[0]] = -1000\n",
        "        P[:, np.where(self.F_mask == True)[0]] = -1000\n",
        "        return np.unravel_index(P.argmax(), P.shape)\n",
        "    \n",
        "    def end_episode(self):\n",
        "        return np.all(self.F_mask == True)\n",
        "    \n",
        "    def get_Fo(self):\n",
        "        return self.F.reshape(-1).copy()\n",
        "    \n",
        "    def get_state(self):\n",
        "        return self.fi.copy(), self.F.reshape(-1).copy(), self.pi.copy()\n",
        "    \n",
        "    def terminal_value(self):\n",
        "        return np.array(sum([self.fi_table[action_fi]==action_F for action_fi, action_F in self.history]) / len(self.history))\n",
        "      \n",
        "    def first_frag(self):\n",
        "      action_fi, action_F = self.history[0]\n",
        "      if self.fi_table[action_fi]==action_F:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wPhX-hUETwA",
        "colab_type": "text"
      },
      "source": [
        "##Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L97Zksi_CIVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class memoryV2():\n",
        "  def __init__(self, max_size):\n",
        "    self.size = max_size*9\n",
        "    self.images = deque(maxlen = max_size*9)\n",
        "  \n",
        "  def addImg(self, fi, Fi, Fo, Mv): #mv is the position in the 81 probability vector of the choosen one\n",
        "    if len(self.images) + 1 == self.size:\n",
        "      del self.images[np.random.randint(self.size-1)]\n",
        "    self.images.append({'fi':fi, 'Fi':Fi, 'Fo':Fo, 'mv':Mv[0]*9+Mv[1]})\n",
        "  \n",
        "  def getMv(self, step):\n",
        "    return self.images[step]['mv']\n",
        "  \n",
        "  def getSample(self, number):\n",
        "    return np.random.choice(self.images, number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81pUM0PG4jFS",
        "colab_type": "text"
      },
      "source": [
        "#execution generation and training\n",
        "\n",
        "\n",
        "\n",
        "*   Generate episodes\n",
        "*   Pick samples in this memory of episodes\n",
        "*   Rate the images picked using the discriminator\n",
        "*   Train both of the discriminator and the generator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QUjLQ5JUG5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateEpisode(network, memory, nb_step, rand_choice, testOn, inputImg):\n",
        "    world  = World(inputImg)\n",
        "    step = 0\n",
        "    fi = []\n",
        "    Fi = []\n",
        "    action = []\n",
        "    while(step < nb_step):\n",
        "        tmpfi, tmpFi, pi = world.get_state()\n",
        "        fi.append(tmpfi)\n",
        "        Fi.append(tmpFi)\n",
        "        P = network.predict([np.expand_dims(tmpfi, axis=0), np.expand_dims(tmpFi, axis=0)])\n",
        "        if testOn > 1:\n",
        "          print(P)\n",
        "        action.append(world.best_legal_move(P.reshape(9,9), rand_choice))\n",
        "        world.move(action[step])\n",
        "        Fo = world.get_Fo()\n",
        "        step = step + 1\n",
        "    for i in range(step):\n",
        "        memory.addImg(fi[i], Fi[i], Fo, action[i])\n",
        "    if testOn > 0:\n",
        "        print(\"image\")\n",
        "        plt.imshow(Fo.reshape(27,27).copy())\n",
        "        plt.show()\n",
        "    return world"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZPgpyhD5J2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getTrainingG(sample, evaluation):\n",
        "    trainLabels = []\n",
        "    count = 0\n",
        "    for i in sample:\n",
        "      a = np.zeros(81)\n",
        "      a[i['mv']] = evaluation[count]\n",
        "      trainLabels.append(a)\n",
        "      count = count + 1\n",
        "    trainDatafi = np.array([d['fi'] for d in sample])\n",
        "    trainDataFi = np.array([d['Fi'] for d in sample])\n",
        "    return trainDatafi, trainDataFi, np.array(trainLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-QZPVN-A3rG",
        "colab_type": "text"
      },
      "source": [
        "## Init of the system\n",
        "\n",
        "Put some episodes in the memory to start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGm-2-Eg5gFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to play with\n",
        "rand_choice = 0.5\n",
        "batchsize = 32\n",
        "maxEpisodes = batchsize*4\n",
        "nb_step = 9 #number of steps in the generated episodes\n",
        "memory1 = memoryV2(maxEpisodes)\n",
        "generator = get_Gnetwork()\n",
        "discriminator = getDnetwork()\n",
        "for i in range(batchsize*2):\n",
        "  generateEpisode(generator, memory1, nb_step, rand_choice, 0, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUxQciFR0sy6",
        "colab_type": "text"
      },
      "source": [
        "##Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZdOQ7Xz1alC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_out_loss = 0\n",
        "D_out_acc = 0\n",
        "G_out_loss = 0\n",
        "G_out_acc = 0\n",
        "solving = 0\n",
        "solvingList = []\n",
        "D_predict_error = 0\n",
        "FoList = []\n",
        "localsolving = 0\n",
        "first_frag = 0\n",
        "\n",
        "for i in range(1000000):\n",
        "  solvingList.clear()\n",
        "  FoList.clear()\n",
        "  \n",
        "  #lower the random exploration rate\n",
        "  if i%100 == 0:\n",
        "    rand_choice = rand_choice - 0.02\n",
        "  \n",
        "  #add new episodes\n",
        "  for j in range(batchsize):\n",
        "    world = generateEpisode(generator, memory1, nb_step, rand_choice, 0, -1)\n",
        "    #getting some metrics\n",
        "    solvingList.append(world.terminal_value())\n",
        "    FoList.append(world.get_Fo())\n",
        "    localsolving = localsolving + world.local_value()\n",
        "    first_frag = first_frag + world.first_frag()\n",
        "  \n",
        "  # error between discriminator and groud truth\n",
        "  D_predict_error = D_predict_error + (sum(abs(np.subtract(solvingList, discriminator.predict(np.array(FoList)).reshape(-1))))/batchsize)\n",
        "  solving = solving + sum(solvingList)\n",
        "        \n",
        "  #get a sample\n",
        "  sample = memory1.getSample(batchsize)\n",
        "  generatedImg = np.array([d['Fo'] for d in sample])\n",
        "  \n",
        "  #generate trainingG\n",
        "  trainDataGfi, trainDataGFi, trainLabelsG = getTrainingG(sample, discriminator.predict(generatedImg))\n",
        "    \n",
        "    \n",
        "  #train discriminator\n",
        "  trainDataD, trainLabelsD = getTrainingD(generatedImg, batchsize, nb_step)\n",
        "  D_loss, D_acc = discriminator.train_on_batch(trainDataD, trainLabelsD)\n",
        "  D_out_loss = D_out_loss + D_loss\n",
        "  D_out_acc = D_out_acc + D_acc    \n",
        "    \n",
        "  #train generator\n",
        "  G_loss, G_acc = generator.train_on_batch([trainDataGfi, trainDataGFi], trainLabelsG)\n",
        "  G_out_loss = G_out_loss + G_loss\n",
        "  G_out_acc = G_out_acc + G_acc\n",
        "  \n",
        "  if i%50 == 0:\n",
        "    print(\"current generated episode\" )\n",
        "    print(i)\n",
        "    plt.imshow(world.get_Fo().reshape(27, 27).copy())\n",
        "    plt.show()\n",
        "    print(\"global solving %:\" + str(solving/(50*32)) + \"     local solving: \" + str(localsolving/(50*32)) + \"     first frag: \" + str(first_frag/(50*32)))\n",
        "    print(\"discriminator:\")\n",
        "    print(\"loss: \" + str(D_out_loss/50) + \"      accuracy: \" + str(D_out_acc/50) + \"     accuracy2: \" + str(D_predict_error/(50*32)))\n",
        "    print(\"generator:\")\n",
        "    print(\"loss: \" + str(G_out_loss/50) + \"      accuracy: \" + str(G_out_acc/50))\n",
        "    \n",
        "                                       \n",
        "    #save in csv\n",
        "    with open('/content/drive/My Drive/M2/Research project/output/MNIST_metric3V2.csv', mode='a') as solving_csv:\n",
        "      solving_csv = csv.writer(solving_csv, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "      solving_csv.writerow([i , solving/(50*32), localsolving/(50*32), first_frag/(50*32), D_out_acc/50, D_predict_error/(50*32), D_out_loss/50, G_out_acc/50, G_out_loss/50])\n",
        "      \n",
        "      \n",
        "    #re init \n",
        "    first_frag = 0\n",
        "    localsolving = 0\n",
        "    solving = 0\n",
        "    D_predict_error = 0\n",
        "    D_out_loss = 0\n",
        "    D_out_acc = 0\n",
        "    G_out_loss = 0\n",
        "    G_out_acc = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X02v4mu7kXB",
        "colab_type": "text"
      },
      "source": [
        "#tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-XaFnq7IBiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test discriminator with real image => 1\n",
        "print(discriminator.predict(getRealImg(10, nb_step)).reshape(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXIQCFCEBWw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test discriminator with images from the generator => 0\n",
        "sample = memory1.getSample(10)\n",
        "generatedImg = np.array([d['Fo'] for d in sample])\n",
        "print(discriminator.predict(generatedImg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz6IcKAtpHuY",
        "colab_type": "text"
      },
      "source": [
        "##Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hmHqQjG4pzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = 100\n",
        "for i in range(100):\n",
        "    test = generateEpisode(generator, memory1, nb_step, 0, 0, (i%1000)+100).get_Fo().reshape(27, 27).copy()\n",
        "    #plt.imshow(data[i%10])\n",
        "    #plt.show()\n",
        "    result = np.sum(np.abs(test - data[(i+100)%data_size]))\n",
        "    #print(\"result:\")\n",
        "    #print(result)\n",
        "    if result > 10:\n",
        "      score = score - 1\n",
        "      if discriminator.predict(np.array([test])) > 0.45 :\n",
        "        mpimg.imsave(str(i+1000) + \"error.png\", test)\n",
        "    #elif i <20:\n",
        "    #  mpimg.imsave(\"perfect/\" +str(i) + \"perfect.png\", test)\n",
        "print(\"score total de:\")\n",
        "print(score/100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPevj2aoR9OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = 1000\n",
        "for i in range(1000):\n",
        "    test = generateEpisode(generator, memory1, nb_step, 0, 0, (i)+10000).get_Fo().reshape(27, 27).copy()\n",
        "    #plt.imshow(data[i%10])\n",
        "    #plt.show()\n",
        "    result = np.sum(np.abs(test - data[(i)+10000]))\n",
        "    #print(\"result:\")\n",
        "    #print(result)\n",
        "    if result > 10:\n",
        "       error = error - 1\n",
        "print(\"erreur total de:\")\n",
        "print(error/1000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}